
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Auditing AI &#8212; TAILOR - D3.3 - Handbook on Trustworthy AI</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Bias" href="bias.html" />
    <link rel="prev" title="Fairness, Equity, and Justice by Design" href="../T3.3.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/TAILOR-logo-coloured.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">TAILOR - D3.3 - Handbook on Trustworthy AI</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Cerca in questo libro ..." aria-label="Cerca in questo libro ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../TAILOR.html">
   Welcome to TAILOR
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../authors.html">
   Complete List of Contributors
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../T3.1.html">
   Explainable AI Systems
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../T3.1/XAI_kinds.html">
     Kinds of Explanations
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.1/feature_importance.html">
       Feature Importance
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.1/saliency_maps.html">
       Saliency Maps
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.1/single_tree.html">
       Single Tree Approximation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../T3.1/XAI_dimensions.html">
     Dimensions of Explanations
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.1/blackbox_transparent.html">
       Black Box Explanation vs Explanation by Design
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.1/model_specific.html">
       Model-Specific vs Model-Agnostic Explainers
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.1/global_local.html">
       Global vs Local Explanations
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../T3.2.html">
   Safety and Robustness
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../T3.2/alignment.html">
     Alignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../T3.2/robustness.html">
     Robustness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../T3.2/reliability.html">
     Reliability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../T3.2/evaluation.html">
     Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../T3.2/negative_side_effects.html">
     Negative side effects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../T3.2/distributional_shift.html">
     Distributional shift
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../T3.2/security.html">
     Security
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../T3.2/adversarial_attack.html">
     Adversarial Attack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../T3.2/data_poisoning.html">
     Data Poisoning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../T3.3.html">
   Fairness, Equity, and Justice by Design
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Auditing AI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bias.html">
     Bias
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="equity.html">
     Discrimination &amp; Equity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fairness.html">
     Fairness notions and metrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="fair_ML.html">
     Fair Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="discrimination.html">
     Grounds of Discrimination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="justice.html">
     Justice
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="segregation.html">
     Segregation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../T3.4/L1.Accountability_and_Reproducibility.html">
   Accountability and Reproducibility
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../T3.4/L2.Accountability.html">
     Accountability
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.4/L3.Wicked_problems.html">
       Wicked problems
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.4/L3.Meaningful_human_control.html">
       Meaningful human control
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.4/L3.The_frame_problem.html">
       The Frame problem
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../T3.4/L2.Reproducibility.html">
     Reproducibility
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../T3.4/L2.Traceability.html">
     Traceability
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.4/L3.Provenance_tracking.html">
       Provenance Tracking
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.4/L3.Continuous_performance_monitoring.html">
       Continuous Performance Monitoring
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../T3.5.html">
   Respect for Privacy
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../T3.5/L1.anonymization.html">
     Data Anonymization and Pseudonymization
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.5/L2.pseudonymization.html">
       Pseudonymization
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../T3.5/L1.privacy_model.html">
     Privacy Models
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../T3.5/L2.differential_privacy.html">
       Differential Privacy
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
      <label for="toctree-checkbox-12">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../T3.5/L3.epsilon_DP.html">
         <span class="math notranslate nohighlight">
          \(\epsilon\)
         </span>
         -Differential Privacy
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../T3.5/L3.epsilon_delta_DP.html">
         (
         <span class="math notranslate nohighlight">
          \(\epsilon\)
         </span>
         ,
         <span class="math notranslate nohighlight">
          \(\delta\)
         </span>
         )-Differential Privacy
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../T3.5/L3.computational_DP.html">
         Computational Differential Privacy
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../T3.5/L3.other_DP.html">
         Other Variants or Generalizations
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.5/L2.k_anonymity.html">
       k-anonymity
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../T3.5/L1.privacy_mechanisms.html">
     Privacy Mechanisms
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../T3.5/L2.perturbation_mechanisms.html">
       Perturbation Mechanisms
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
      <label for="toctree-checkbox-14">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../T3.5/L3.local_perturbation.html">
         Local Perturbation
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../T3.5/L3.laplace.html">
         Laplace Mechanism
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../T3.5/L3.exponential.html">
         Exponential Mechanism
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../T3.5/L3.randomness_alignments.html">
         Randomness Alignments
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../T3.5/L1.attacks.html">
     Attacks on anonymization schemes
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
    <label for="toctree-checkbox-15">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.5/L2.reidentification.html">
       Re-identification Attack
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.5/L2.membership.html">
       Membership Attack
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.5/L2.reconstruction.html">
       Reconstruction Attack
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../T3.6.html">
   Sustainability
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../T3.6/greenAI.html">
     Green AI
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
    <label for="toctree-checkbox-17">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../T3.6/power_aware.html">
       Power-aware Computing
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../T3.6/cloud_computing.html">
     Cloud Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../T3.6/edge_computing.html">
     Edge Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../T3.6/data_centre.html">
     Data Centre
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../T3.6/cradle_to_cradle.html">
     Cradle-to-cradle Design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../T3.6/resource_prediction.html">
     Resource Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../T3.6/resource_allocation.html">
     Resource Allocation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../AnalyticaIndex.html">
   Index
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/2CC2.html">
     2CC2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Accountability.html">
     Accountability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Alignment.html">
     Alignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Ante-hoc%20Explanation.html">
     Ante-hoc Explanation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Assurance.html">
     Assurance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Attacks%20on%20Anonymization%20Schemes.html">
     Attacks on Anonymization Schemes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Attacks%20on%20Partition-based%20Algorithms.html">
     Attacks on Partition-based Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Attacks%20on%20Pseudonymised%20Data.html">
     Attacks on Pseudonymised Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Auditing.html">
     Auditing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Autonomy%20Levels.html">
     Autonomy Levels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Bias.html">
     Bias
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/C2C.html">
     C2C
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Certification%20Standards.html">
     Certification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Cloud%20Computing.html">
     Cloud Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Computational%20Differential%20Privacy.html">
     Computational Differential Privacy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Corrigibility.html">
     Corrigibility
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Counterfactual%20Explanations.html">
     Counterfactual explanations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/cradle%202%20cradle.html">
     Cradle 2 cradle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Cradle.html">
     Cradle-to-cradle Design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Data%20Anonymization.html">
     Data Anonymization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Data%20Center.html">
     Data Center
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Data%20Minimisation.html">
     Data Minimisation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Data%20sanitization.html">
     Data Sanitization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/deFinetti%20Attack.html">
     deFinetti Attack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Differential%20Privacy%20models.html">
     Differential Privacy Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/epsilon_delta-differential_privacy.html">
     (
     <span class="math notranslate nohighlight">
      \(\epsilon\)
     </span>
     ,
     <span class="math notranslate nohighlight">
      \(\delta\)
     </span>
     )-Differential Privacy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Epsilon-differential_privacy.html">
     <span class="math notranslate nohighlight">
      \(\epsilon\)
     </span>
     -Differential Privacy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Differential%20Privacy%20-%20Other%20Variants%20or%20Generalizations.html">
     Differential Privacy - Other Variants or Generalizations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Dimensions%20of%20Explanations.html">
     Dimensions of Explanations (Explainable AI Systems)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Discrimination.html">
     Discrimination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Distributional%20Shift.html">
     Distributional Shift
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Edge%20Computing.html">
     Edge Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Electricity%20Price%20Forecast.html">
     Electricity Price Forecast
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Energy%20Aware.html">
     Energy-aware Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Enforcement.html">
     Enforcement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/epsilon-indistinguishability.html">
     <span class="math notranslate nohighlight">
      \(\epsilon\)
     </span>
     -Indistinguishability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Equity.html">
     Equity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Evaluating%20Explanations.html">
     Evaluating Explanations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Exponential%20Mechanism.html">
     Exponential Mechanism
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Fair%20Machine%20Learning.html">
     Fair Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Fairness.html">
     Fairness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Features%20Importance.html">
     Feature Importance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Fog%20Computing.html">
     Fog Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Generality.html">
     Generality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/General%20Privacy-related%20Attacks.html">
     General Privacy-related Attacks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Global%20Explanations.html">
     Global Explanations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Global%20Recoding.html">
     Global Recording
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Goal%20Stability.html">
     Goal Stability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Green%20AI.html">
     Green AI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Green%20Computing.html">
     Green Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Green%20IT.html">
     Green IT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Human-in-the-loop.html">
     Human-in-the-loop
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/ICT%20sustainability.html">
     ICT sustainability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Impact%20Assessment%20of%20Trustworthy%20AI.html">
     Impact Assessment of Trustworthy AI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Interpretability.html">
     Interpretability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Interruptibility.html">
     Interruptibility
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Justice.html">
     Justice
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/K-Anonymity.html">
     K-anonymity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Laplace%20Mechanism.html">
     Laplace Mecanism
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Local%20Explanations.html">
     Local Explanations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Local%20perturbation.html">
     Local Perturbation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Local%20Recoding.html">
     Local Recording
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Meaningful%20human%20control.html">
     Meaningful Human Control
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Membership%20Inference%20Attacks.html">
     Membership Inference Attack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Mesh%20Computing.html">
     Mesh Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Minimality%20Attack.html">
     Minimality Attack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Model-Agnostic.html">
     Model Agnostic (Explainable AI Systems)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Model-Specific.html">
     Model Specific (Explainable AI Systems)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Mondrian.html">
     Mondrian
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Monitoring.html">
     Monitoring
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Moral%20responsibility.html">
     Moral Responsability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Multidimensional%20Recoding.html">
     Multidimensional Recording
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Negative%20Side%20Effects.html">
     Negative Side Effects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Nice%20properties%20of%20Privacy%20Models.html">
     Nice Properties of Privacy Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Partition-Based%20Algorithms.html">
     Partition-Based Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Perturbation%20Mechanisms.html">
     Perturbation Mechanisms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Post-hoc%20Explanations.html">
     Post-hoc Explanation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Power%20Aware.html">
     Power-aware Computing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy%20algorithm.html">
     Privacy Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy%20Mechanism.html">
     Privacy Mechanism
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy%20model.html">
     Privacy model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Privacy-Preserving%20Data%20Publishing.html">
     Privacy-Preserving Data Publishing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Problem%20of%20many%20hands.html">
     Problem of Many Hands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Randomized%20response.html">
     Randomized response
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Reconstruction%20Attacks.html">
     Reconstruction Attacks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Re-identification%20Attack.html">
     Re-identification Attack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Regenerative.html">
     Regenerative Design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Reliability.html">
     Reliability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Repeatability.html">
     Repeatability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Replicability.html">
     Replicability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Reproducibility.html">
     Reproducibility
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Resource%20Allocation.html">
     Resource Allocation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Resource%20Prediction.html">
     Resource Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Resource%20Scheduling.html">
     Resource Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Reward%20Hacking.html">
     Reward Hacking
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Robustness.html">
     Robustness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Rules%20List%20and%20Rules%20Set.html">
     Rules List and Rules Set
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Safety%20Criticality.html">
     Safety Criticality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Safety%20Standards.html">
     Safety Standards
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Saliency%20Maps.html">
     Saliency Maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Scalable%20Oversight%20Problem.html">
     Scalable Oversight Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Security%20under%20post-processing.html">
     Security under Post-processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Segregation.html">
     Segregation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Self-composition.html">
     Self-composition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Side%20Effects.html">
     Side Effects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Single%20Tree%20Approximation.html">
     Single Tree Approxiamation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Specification.html">
     Specification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Stochastic%20Forecast.html">
     Stochastic Forecast
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Testing.html">
     Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Traceability.html">
     Traceability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Training%20Corruption.html">
     Training Corruption
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Transparency.html">
     Transparency
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Uncertainty.html">
     Uncertainty
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Validation.html">
     Validation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Verification.html">
     Verification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Workload%20Forecast.html">
     Workload Forecast
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../index/Workload%20Prediction.html">
     Workload Prediction
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Attiva / disattiva la navigazione" aria-controls="site-navigation"
                title="Attiva / disattiva la navigazione" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Scarica questa pagina"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/T3.3/auditing.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Scarica il file sorgente" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Stampa in PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="git@github.com:prafra/jupyter-book-TAILOR-D3.2.git"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Repository di origine"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="git@github.com:prafra/jupyter-book-TAILOR-D3.2.git/issues/new?title=Issue%20on%20page%20%2FT3.3/auditing.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Apri un problema"><i class="fas fa-lightbulb"></i>questione aperta</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Modalità schermo intero"
        title="Modalità schermo intero"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contenuti
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#in-brief">
   In brief
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more-in-detail">
   More in Detail
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliography">
   Bibliography
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="auditing-ai">
<h1>Auditing AI<a class="headerlink" href="#auditing-ai" title="Permalink to this headline">¶</a></h1>
<div class="section" id="in-brief">
<h2>In brief<a class="headerlink" href="#in-brief" title="Permalink to this headline">¶</a></h2>
<p>TODO: missing journal in koshiyama2021towards</p>
</div>
<div class="section" id="more-in-detail">
<h2>More in Detail<a class="headerlink" href="#more-in-detail" title="Permalink to this headline">¶</a></h2>
<p>One of the measures to ensure that AI is used responsibly is the
initiation of auditing practices as they facilitate to verify if the
system works as intended.</p>
<p>Audits can be conducted either in-house or by external parties. The
former requires internal evaluation regarding whether systems are fit,
the human elements involved with the system are appropriate and
monitored, and the technical elements of the system are in perfect
condition and function correctly <span id="id1">[<a class="reference internal" href="#id2458">2</a>, <a class="reference internal" href="#id2459">3</a>]</span>.
The latter involves both regulators and third-parties verifying
compliance <span id="id2">[<a class="reference internal" href="../T3.4/L2.Accountability.html#id2460">3</a>]</span>. Interestingly, critical external
audits encompasses “disparate methods of journalist, technicians, and
social scientist who have examined the consequences of already-deployed
algorithmic systems and who have no formal relationship which the
institutions designing or integrating the audited systems”
<span id="id3">[<a class="reference internal" href="#id2451">5</a>]</span>. Well-known examples of these practices
such as the Propublica’s examination of Northpoint recivism prediction
API <span id="id4">[<a class="reference internal" href="#id2453">6</a>]</span> or the Gender Shade Project <span id="id5">[<a class="reference internal" href="#id2452">7</a>]</span>,
have played a crucial role pointing out harmful application of algorithm
systems to draw the attention of the society and require companies an
active role setting out governance and accountability mechanism.</p>
<p>As a result of these social demands, internal governance mechanisms
<span id="id6">[<a class="reference internal" href="#id2451">5</a>]</span> have been introduced from within the own
companies that design and deployed the algorithmic systems. The goal is
to propose technical and organisational procedures, among which are
detailed frameworks for algorithm auditing <span id="id7">[<a class="reference internal" href="#id2454">8</a>]</span>, able to
identify and address possible risk and impacts while ensuring robust and
trustful accountability. In essence, precise and well-documented audits
facilitate later scrutiny offering records on the reasons for the audit
to be initiated, the procedures that were followed as well as the
conclusions that were reached and, if carried out, the remedies or
measures that were adopted.</p>
<p>To this regard, more and more voices consider audits as indispensable
accountability mechanism to ensure the compliance of AI systems along
their life-cycle with the different applicable legislation, concerning
in particular privacy and data protection law <span id="id8">[<a class="reference internal" href="#id2457">9</a>]</span>.
Moreover, AI auditing can benefit from extensive literature in more
mature disciplines, such as audit studies in social sciences
<span id="id9">[<a class="reference internal" href="#id2525">10</a>]</span> and empirical economics
<span id="id10">[<a class="reference internal" href="#id2392">1</a>]</span>. Audits facilitate private entities the
provision of documentation when requested by public bodies, favouring a
systematic governance <span id="id11">[<a class="reference internal" href="#id2456">11</a>]</span> of AI systems through a
general transparency and enforcement regime. This joint effort between
public and private institutions would, in turn, result in collaborative
governance scheme <span id="id12">[<a class="reference internal" href="#id2456">11</a>]</span>.</p>
<p>The upcoming EU Artificial Intelligence Act can be seen as a proposal to
establish a Europe-wide ecosystem for conducting AI auditing
<span id="id13">[<a class="reference internal" href="#id2521">12</a>]</span> and in line with that idea more and more
research is done on auditing procedures for algorithms (for reviews see
<span id="id14">[<a class="reference internal" href="#id2530">13</a>, <a class="reference internal" href="#id2531">14</a>]</span>). For example,
<span id="id15">[<a class="reference internal" href="#id2454">8</a>]</span> propose a framework for internal AI auditing which
includes both ethical aspects (a social impact assessment and ethical
risk analysis chart) and technical audits (such as adversarial testing
and a Failure Modes and Effect Analysis). Such audits are often
supported by technical documentation, such as the Datasheets for
Datasets proposal <span id="id16">[<a class="reference internal" href="#id2524">15</a>]</span> to maintain information on
datasets used to train AI systems. Such documentation can both help to
ensure that AI systems are deployed for tasks in line with the data they
were trained on and help to spot ethical risks stemming from the data
<span id="id17">[<a class="reference internal" href="#id2526">16</a>]</span>, such as <a class="reference internal" href="bias.html"><span class="doc std std-doc">biases</span></a>.</p>
<p>Ethical risks can also be the sole focus of AI audits, as in
ethics-based auditing (proposed for AI in <span id="id18">[<a class="reference internal" href="#id2522">17</a>]</span>). While
still in development, several options are emerging where: “functionality
audits focus on the rationale behind decisions; code audits entail
reviewing the source code of an algorithm; and impact audits investigate
the types, severity, and prevalence of effects of an algorithm’s
outputs.” <span id="id19">[<a class="reference internal" href="#id2433">18</a>]</span> For these audits in particular determining
what is measured can be a challenge, as it is difficult to define clear
metrics on which ethical aspects of AI systems can be evaluated.
<em>Fairness metrics</em> (cf. the entry on ) can certainly help here, but as
discussed there is a difficulty in the selection of the right metric and
even then there are limitations and trade-offs with other metrics. In
addition, for the integration of AI ethics in ESG (Environmental, Social
and Governance) reporting towards investors <span id="id20">[<a class="reference internal" href="#id2528">19</a>]</span>
such fairness metrics need not give sufficient insights into whether
algorithms are used responsibly at an organisational level. Existing ESG
criteria for organizational audits may help here, as well as work on
KPIs for Responsible Research and Innovation <span id="id21">[<a class="reference internal" href="#id2532">20</a>]</span>.
Despite all this work on metrics, it is however still an open question
to what extent ethics can be captured in numbers the way other aspects
of audits are, with some arguing that it is impossible to develop
benchmarks for how ethical an AI system is <span id="id22">[<a class="reference internal" href="#id2527">21</a>]</span>.
Instead, they argue, the focus should be on values and value trade-offs.</p>
<p>Z-Inspection, another auditing framework proposed based on the European
High Level Expert Group’s Guidelines for Trustworthy AI
<span id="id23">[<a class="reference internal" href="#id2535">22</a>]</span>, takes values as its starting point <span id="id24">[<a class="reference internal" href="#id2533">23</a>]</span>.
As can also be seen in a case study for the framework involving an
algorithm that recognizes cardiac arrests in emergency calls
<span id="id25">[<a class="reference internal" href="#id2534">24</a>]</span> this framework proceeds from a wide
identification of stakeholders and their values to the analysis of
(socio-)technical scenario’s to reach an identification and
(potentially) resolution of ethical, technical and legal issues of an AI
system. Ultimately this still depends on the translation of values into
metrics, and so the main challenge of developing such metrics stands
regardless of one’s auditing approach.</p>
<p>Standards represent a natural framework for the proceduralization of
audits. Certification by neutral third party states compliance to
certain standards as the result of auditing. Several draft proposals are
being prepared which include (at least implicitely) elements for
conducting audits, such as the following:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.iso.org/standard/77607.html">ISO/IEC TR 24027:2021</a> -
Artificial intelligence (AI) — Bias in AI systems and AI aided
decision making.</p></li>
<li><p><a class="reference external" href="https://standards.ieee.org/ieee/7010/7718/">IEEE 7010-2020</a>:
Recommended Practice for Assessing the Impact of Autonomous and
Intelligent Systems on Human Well-being.</p></li>
<li><p><a class="reference external" href="https://standards.ieee.org/ieee/2863/10142/">IEEE P2863</a> -
Recommended Practice for Organizational Governance of Artificial
Intelligence.</p></li>
<li><p><a class="reference external" href="https://engagestandards.ieee.org/ieeecertifaied.html">IEEE CertifAIEd</a> –
Ontological Specification for Ethical Accountability</p></li>
<li><p><a class="reference external" href="https://engagestandards.ieee.org/ieeecertifaied.html">IEEE CertifAIEd</a> –
Ontological Specification for Ethical Algorithmic Bias.</p></li>
<li><p><a class="reference external" href="https://www.nist.gov/itl/ai-risk-management-framework">NIST AI Risk Management Framework</a>.</p></li>
</ul>
<p>However, there is not yet a formal professional standard to guide
auditors of AI systems, yet some <a href="https://ec.europa.eu/futurium/en/system/files/ged/auditing-artificial-intelligence.pdf" target=_blank>guidelines</a> exist.</p>
</div>
<div class="section" id="bibliography">
<h2>Bibliography<a class="headerlink" href="#bibliography" title="Permalink to this headline">¶</a></h2>
<p id="id26"><dl class="citation">
<dt class="label" id="id2392"><span class="brackets"><a class="fn-backref" href="#id10">1</a></span></dt>
<dd><p>Andrea Romei and Salvatore Ruggieri. A multidisciplinary survey on discrimination analysis. <em>Knowl. Eng. Rev.</em>, 29(5):582–638, 2014.</p>
</dd>
<dt class="label" id="id2458"><span class="brackets"><a class="fn-backref" href="#id1">2</a></span></dt>
<dd><p>Ada Lovelace and UK DataKind. Examining the black box: tools for assessing algorithmic systems. Technical Report, Technical report, AdaLovelace Institute, https://ico. org. uk/media/about …, 2020.</p>
</dd>
<dt class="label" id="id2459"><span class="brackets"><a class="fn-backref" href="#id1">3</a></span></dt>
<dd><p>Emre Kazim, Danielle Mendes Thame Denny, and Adriano Koshiyama. Ai auditing and impact assessment: according to the uk information commissioner’s office. <em>AI and Ethics</em>, 1(3):301–310, 2021.</p>
</dd>
<dt class="label" id="id2460"><span class="brackets"><a class="fn-backref" href="#id2">4</a></span></dt>
<dd><p>Jennifer Cobbe, Michelle Seng Ah Lee, and Jatinder Singh. Reviewable automated decision-making: a framework for accountable algorithmic systems. In <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>, 598–609. 2021.</p>
</dd>
<dt class="label" id="id2451"><span class="brackets">5</span><span class="fn-backref">(<a href="#id3">1</a>,<a href="#id6">2</a>)</span></dt>
<dd><p>Jacob Metcalf, Emanuel Moss, Elizabeth Anne Watkins, Ranjit Singh, and Madeleine Clare Elish. Algorithmic impact assessments and accountability: the co-construction of impacts. In <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>, 735–746. 2021.</p>
</dd>
<dt class="label" id="id2453"><span class="brackets"><a class="fn-backref" href="#id4">6</a></span></dt>
<dd><p>Jeff Larson, Surya Mattu, Lauren Kirchner, and Julia Angwin. How we analyzed the compas recidivism algorithm. <em>ProPublica (5 2016)</em>, 9(1):3–3, 2016.</p>
</dd>
<dt class="label" id="id2452"><span class="brackets"><a class="fn-backref" href="#id5">7</a></span></dt>
<dd><p>Joy Adowaa Buolamwini. <em>Gender shades: intersectional phenotypic and demographic evaluation of face datasets and gender classifiers</em>. PhD thesis, Massachusetts Institute of Technology, 2017.</p>
</dd>
<dt class="label" id="id2454"><span class="brackets">8</span><span class="fn-backref">(<a href="#id7">1</a>,<a href="#id15">2</a>)</span></dt>
<dd><p>Inioluwa Deborah Raji, Andrew Smart, Rebecca N. White, Margaret Mitchell, Timnit Gebru, Ben Hutchinson, Jamila Smith-Loud, Daniel Theron, and Parker Barnes. Closing the AI accountability gap: defining an end-to-end framework for internal algorithmic auditing. In <em>FAT*</em>, 33–44. ACM, 2020.</p>
</dd>
<dt class="label" id="id2457"><span class="brackets"><a class="fn-backref" href="#id8">9</a></span></dt>
<dd><p>Bryan Casey, Ashkon Farhangi, and Roland Vogl. Rethinking explainable machines: the gdpr's' right to explanation'debate and the rise of algorithmic audits in enterprise. <em>Berkeley Tech. LJ</em>, 34:143, 2019.</p>
</dd>
<dt class="label" id="id2525"><span class="brackets"><a class="fn-backref" href="#id9">10</a></span></dt>
<dd><p>Briana Vecchione, Karen Levy, and Solon Barocas. Algorithmic auditing and social justice: lessons from the history of audit studies. In <em>EAAMO</em>, 19:1–19:9. ACM, 2021.</p>
</dd>
<dt class="label" id="id2456"><span class="brackets">11</span><span class="fn-backref">(<a href="#id11">1</a>,<a href="#id12">2</a>)</span></dt>
<dd><p>Margot E Kaminski and Gianclaudio Malgieri. Algorithmic impact assessments under the GDPR: producing multi-layered explanations. <em>International Data Privacy Law</em>, pages 19–28, 2020.</p>
</dd>
<dt class="label" id="id2521"><span class="brackets"><a class="fn-backref" href="#id13">12</a></span></dt>
<dd><p>Jakob Mökander, Maria Axente, Federico Casolari, and Luciano Floridi. Conformity assessments and post-market monitoring: a guide to the role of auditing in the proposed european ai regulation. <em>Minds and Machines</em>, pages 1–28, 2021.</p>
</dd>
<dt class="label" id="id2530"><span class="brackets"><a class="fn-backref" href="#id14">13</a></span></dt>
<dd><p><strong>missing journal in koshiyama2021towards</strong></p>
</dd>
<dt class="label" id="id2531"><span class="brackets"><a class="fn-backref" href="#id14">14</a></span></dt>
<dd><p>Danaë Metaxa, Joon Sung Park, Ronald E Robertson, Karrie Karahalios, Christo Wilson, Jeff Hancock, Christian Sandvig, and others. Auditing algorithms: understanding algorithmic systems from the outside in. <em>Foundations and Trends® in Human–Computer Interaction</em>, 14(4):272–344, 2021.</p>
</dd>
<dt class="label" id="id2524"><span class="brackets"><a class="fn-backref" href="#id16">15</a></span></dt>
<dd><p>Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé Iii, and Kate Crawford. Datasheets for datasets. <em>Communications of the ACM</em>, 64(12):86–92, 2021.</p>
</dd>
<dt class="label" id="id2526"><span class="brackets"><a class="fn-backref" href="#id17">16</a></span></dt>
<dd><p>Karen L Boyd. Datasheets for datasets help ml engineers notice and understand ethical issues in training data. <em>Proceedings of the ACM on Human-Computer Interaction</em>, 5(CSCW2):1–27, 2021.</p>
</dd>
<dt class="label" id="id2522"><span class="brackets"><a class="fn-backref" href="#id18">17</a></span></dt>
<dd><p>Jakob Mökander and Luciano Floridi. Ethics-based auditing to develop trustworthy ai. <em>Minds and Machines</em>, 31(2):323–327, 2021.</p>
</dd>
<dt class="label" id="id2433"><span class="brackets"><a class="fn-backref" href="#id19">18</a></span></dt>
<dd><p>Jakob Mökander, Jessica Morley, Mariarosaria Taddeo, and Luciano Floridi. Ethics-based auditing of automated decision-making systems: nature, scope, and limitations. <em>Science and engineering ethics</em>, 27(4):1–30, 2021.</p>
</dd>
<dt class="label" id="id2528"><span class="brackets"><a class="fn-backref" href="#id20">19</a></span></dt>
<dd><p>Matti Minkkinen, Anniina Niukkanen, and Matti Mäntymäki. What about investors? ESG analyses as tools for ethics-based AI auditing. <em>AI &amp; SOCIETY</em>, pages 1–15, 2022.</p>
</dd>
<dt class="label" id="id2532"><span class="brackets"><a class="fn-backref" href="#id21">20</a></span></dt>
<dd><p>Zenlin Kwee, Emad Yaghmaei, and Steven Flipse. Responsible research and innovation in practice an exploratory assessment of key performance indicators (kpis) in a nanomedicine project. <em>Journal of Responsible Technology</em>, 5:100008, 2021.</p>
</dd>
<dt class="label" id="id2527"><span class="brackets"><a class="fn-backref" href="#id22">21</a></span></dt>
<dd><p>Travis LaCroix and Alexandra Sasha Luccioni. Metaethical perspectives on'benchmarking'ai ethics. <em>arXiv preprint arXiv:2204.05151</em>, 2022. URL: <a class="reference external" href="https://arxiv.org/abs/2204.05151">https://arxiv.org/abs/2204.05151</a>.</p>
</dd>
<dt class="label" id="id2535"><span class="brackets"><a class="fn-backref" href="#id23">22</a></span></dt>
<dd><p>Nathalie Smuha. Ethics guidelines for trustworthy AI. In <em>AI &amp; Ethics, Date: 2019/05/28-2019/05/28, Location: Brussels (Digityser), Belgium</em>. 2019.</p>
</dd>
<dt class="label" id="id2533"><span class="brackets"><a class="fn-backref" href="#id24">23</a></span></dt>
<dd><p>Roberto V Zicari, John Brodersen, James Brusseau, Boris Düdder, Timo Eichhorn, Todor Ivanov, Georgios Kararigas, Pedro Kringen, Melissa McCullough, Florian Möslein, and others. Z-inspection®: a process to assess trustworthy AI. <em>IEEE Transactions on Technology and Society</em>, 2(2):83–97, 2021.</p>
</dd>
<dt class="label" id="id2534"><span class="brackets"><a class="fn-backref" href="#id25">24</a></span></dt>
<dd><p>Roberto V Zicari, James Brusseau, Stig Nikolaj Blomberg, Helle Collatz Christensen, Megan Coffee, Marianna B Ganapini, Sara Gerke, Thomas Krendl Gilbert, Eleanore Hickman, Elisabeth Hildt, and others. On assessing trustworthy ai in healthcare. machine learning as a supportive tool to recognize cardiac arrest in emergency calls. <em>Frontiers in Human Dynamics</em>, pages 30, 2021.</p>
</dd>
</dl>
</p>
<hr class="docutils" />
<p>This entry was written by Alejandra Bringas Colmenarejo, Stefan Buijsman, and Salvatore Ruggieri.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./T3.3"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../T3.3.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Fairness, Equity, and Justice by Design</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="bias.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Bias</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          Di TAILOR WP3 members; see <a href="https://prafra.github.io/jupyter-book-TAILOR-D3.2/authors.html" target="_blank">here</a> for the complete list of contributors.<br/>
        
            &copy; Diritto d'autore 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>