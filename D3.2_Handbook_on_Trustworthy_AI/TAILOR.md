# The TAILOR Handbook of Trustworthy AI

## An encyclopedia of the major scientific and technical terms related to Trustworthy Artificial Intelligence

**TAILOR: Foundations of Trustworthy AI â€“ Integrating Reasoning, Learning and Optimization**

Add an introduction to the first page.
Add an Executive summary to the first page. This should be stand-alone, so that we can use it in formal reporting, for websites, social media etc.


This book (to be consolidated in the second phase of the project) represents the first period deliverable of the TAILOR project, providing an encyclopedia of the major terms related to trustworthiness.

## About the TAILOR Handbook

This is a working document for the Version 1 of the *D3.3 Handbook on Trustworthy AI*, the TAILOR WP3 Handbook on Trustworthy AI. This
is a <a href="https://tailor-network.eu" terget=_blank>TAILOR</a> project deliverable with two versions: Version 1 (M22) and Version 2 (M46).

The Handbook on Trustworthy AI assumes an encyclopedia-like structure and is presented in the form of a publically accessible WIKI. 
To do so, the Jupiter Book framework has been used.
In the long term, the Handbook is meant to become a point of reference for resources (key concepts, tools, documentation, tutorials, teaching material, etc.) related to Trustworthy AI.

Here, you can find information about the topics of each of the task of WP3, summarizing one of the aspects of Trustworthy AI; the order of the chapters that are in this Handbook simply reflects the order of the task in the workpackage. 
In particolar, in this Encyclopedia you can find definition related to:
- {doc}`../T3.1/T3.1`. In this part of the Handbook, we will provide an overview of the main properties that an explanation should have and of the several methods to provide multimodal explanations; moreover, our focus will be also on overcome the need of expaining opaque model and, instead, move towards the use of transparent models. 
- {doc}`../T3.2/T3.2`. In this section of the Encyclopedia, we will analyze the challenges in developing AI systems that are safe, reliable, and robust; we will also provide a way to evaluate this aspects in practice, and we will promote the dynamic evaluation in managing risk during the normal use of AI systems.
- {doc}`../T3.3/T3.3`. In this chapter, we will start recalling what the grounds of discrimination are, how we can define a bias or segregation; then, we will make a step in defining what fair machine learning could be, and what are the metrics we can adopt to measure (un)fairness.
- {doc}`../T3.4/L1.Accountability_and_Reproducibility`. Here, we analyze the two souls of this topic, i.e., the two interrelated concepts of {doc}`../T3.4/L2.Accountability` and {doc}`../T3.4/L2.Reproducibility`: the former term is more related to responsability, blameworthiness, liability, and prevent misuse, where the latter term is more related to measures, quality standards, and procedures to model the development of learning methods for AI.
- {doc}`../T3.5/T3.5`. This section will provide an overview of the main attack that can put at risk individual privacy, we will explain the difference between pseudonymization and actual anonymization, and we will describe the main family of privacy models.
- {doc}`../T3.6/T3.6`. The last chapter of the Handbook is focus of one of the newest challenge that our society is facing, in particular, our focus is to provide solutions for optimizing both the resources used in AI systems and the computation itself.

Finally, we report a final chapter, where you can find an {doc}`main/AnalyticaIndex`, which lists all entries in alphabetical order; in each term you can find a reference to a short definition of the entry and where it is used within the Handbook, with the link to go more in dept with the definition. Potential synonyms have their own entries in this index.

## Executive Summary
