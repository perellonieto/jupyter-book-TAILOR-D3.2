# Respect for Privacy

## In Brief

Respect for Privacy is an ethical aspect studied in the <a href="https://tailor-network.eu/" target=_blank>TAILOR project</a> for ensuring personal data protection that is at the core of the General
Data Protection Regulation (GDPR) {cite}`gdpr`. GDPR, in its <a href="https://gdpr-info.eu/art-5-gdpr/" target=_blank>Article 5</a>, promote *privacy by design* in the form of a certain number of general principles for ensuring *privacy as the default* in the whole chain of data processing for a given task. We outline the challenges and solutions for enforcing privacy by design approaches.

## Abstract 

When protecting personal data, we are faced to the dilemma of disclosing no sensitive data while learning useful information about a population.
One approach for solving this tension between privacy and utility is based on *data encryption* and consists in developping secure computation protocols able to learn models or to compute statistics on encrypted data. A lot of scientific literature {cite}`CastellucciaCMT09` {cite}`ToNP16` {cite}`MirvalBP21` {cite}`CGLY18` has been exploring this security-based approach depending on the target computational task.
Another approach consists in conducting data analysis tasks on datasets made anonymous by the application of some {doc}`./T3.5/L1.privacy_mechanisms`.
according to some {doc}`./T3.5/L1.privacy_model`. Anonymization must no be reduced to *pseudonymization* (see {doc}`./T3.5/L2.reidentification`), which is defined in GDPR Article 4 as "the processing
of personal data in such a way that the data cannot be attributed to a specific data subject without the use of additional information."
Anonymization, as defined in GDPR (see <a href="https://gdpr-info.eu/recitals/no-26/" target=_blank>Recital 26</a>), refers to a process that removes any possibility of identifying a person even with additional information. In the resulting anonymized data, the connection should be completely lost between data and the individuals. Based on such a definition, anonymization is very difficult to model formally and to verify algorithmically. We will briefly survey the main privacy models and their properties, as well as the main privacy mechanisms which can be applied for enforcing the corresponding privacy properties or for providing strong guarantees of robustness to attacks.

## Motivation and Background

Publishing datasets plays an essential role in open data research and in promoting transparency of government agencies. Unfortunately, the process of data publication can be highly risky as it may disclose individuals' sensitive information. Hence, an essential step before publishing datasets is to remove any uniquely identifiable information from them. This is called **{pseudonymization}** (NdFrancesca: I need to add the link here, and in the following: at the moment, there is no Pseudonymization entry, as the description is included in the re-identification attack) and consists in masking or replacing by pseudonyms values of properties that directly identify persons such as their name, address, postcode, telephone number, photograph or image, or some other unique personal characteristic.

**{Pseudonymization}** is not sufficient however for preserving the privacy of users. Adversaries can re-identify individuals in datasets based on common attributes called quasi-identifiers or may have prior knowledge about the users. Such side information enables them to reveal sensitive information that can cause physical, financial, and reputational harms to people.

Therefore, it is crucial to assess carefully *privacy risks* before the publication of datasets. Detection of privacy breaches should come with [explanations](./T3.1.md) that can then be used to guide the choice of the appropriate {anonymization mechanisms} to mitigate the detected privacy risks. *Anonymization* should provide provable guarantees for privacy properties induced by some {doc}`./T3.5/L1.privacy_model`. {doc}`./T3.5/L2.differential_privacy` and {doc}`./T3.5/L2.k_anonymity` are the two main privacy models for which {doc}`./T3.5/L1.privacy_mechanisms` have been designed. They enjoy different properties based on the type of perturbations or transfomations applied on the data to anonymize.

The strength of pseudonymization and anonymization techniques can be assessed by their robustness to [privacy attacks](./T3.5/attacks.md) that aim at re-identifying individuals in datasets based on common attributes called quasi-identifiers or on prior knowledge.

## Guidelines 

*EDBP* has published several guidelines. The EDPB <a href="https://ec.europa.eu/newsroom/article29/items/611236" target=_blank>Guidelines on Data Protection Impact Assessment</a>
focus on determining whether a processing operation is likely to result in a high risk to the data subject or not. It provides guidance on how to assess data protection risks and how to carry out a data protection risk assessment.

*Data minimisation* is a strong recommendation to limit the collection of personal information to what is directly relevant and necessary to accomplish a specified purpose, and to retain the data only for as long as is necessary to fulfil that purpose.

The most authoritative guideline on <a href="https://edpb.europa.eu/our-work-tools/our-documents/guidelines/guidelines-42019-article-25-data-protection-design-and" target=_blank>data protection "by design and by default"</a> outlines the data subject's rights and freedoms and the data protection principles that are illustrated through examples of practical cases. It emphasizes the obligation for controllers to stay up to date on technological advances on handling data protection risks, and to implement and update the measures and safeguards taking into account the evolving technological landscape.

## Software Frameworks Supporting Dimension (TBA)

## Main Keywords (TBA)

{Pseudonymization} , {anonymization mechanisms } , {privacy models },
{Differential privacy} , {k-anonymity} , { privacy attacks}

## Bibliography

```{bibliography}
:style: unsrt
:filter: docname in docnames
```

