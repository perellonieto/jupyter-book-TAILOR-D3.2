# Guidelines

> Authors:
> - Riccardo Albertoni - Istituto di Matematica Applicata e Tecnologie Informatiche "Enrico Magenes", Consiglio Nazionale delle Ricerche (IMATI-CNR), Via De Marini, 6, 16149 Genova, Italy
> - Sara Colantonio - Institute of Information Science and Technologies "A. Faedo" of the National Research Council of Italy (ISTI-CNR), Via G. Moruzzi, 1, 56124 Pisa, Italy
> - Piotr Skrzypczyński - Institute of Robotics and Machine Intelligence,
> Poznań University of Technology, ul. Piotrowo 3A, 60-965 Poznań, Poland
> - Jerzy Stefanowski - Institute of Computing Science, Poznań University of Technology, ul. Piotrowo 2, 60-965 Poznań, Poland

Definitions of the different reproducibility-related terms are often
accompanied by badges and guidelines helping people in making the
definitions operational.

-   Some definitions differentiate the notion of reproducibility
    according to the kind of resource shared. For example
    {cite}`heil_et_al_2021` focus on *computational reproducibility* with
    **bronze, silver, gold** standards. {cite}`gundersen_kjensmo_2018` and
    {cite}`Gundersen_2021` propose different increasing levels *R1, R2, R3, R4*
    depending on whether experiment descriptions, codes, data and
    experiment are stored. @ACMv1.1 recommends that three separate
    badges related to artefact review be associated with research
    articles in ACM publications: Artifacts Evaluated, Artifacts
    Available and Results Validated.

-   Guidelines ease the description of experiments. For example,
    {cite}`pineau_et_al_2020` provides a special Machine learning
    reproducibility checklist; datasheets {cite}`gebru_datasheets_2020`,
    model cards {cite}`mitchell_modelcards_2019` and factsheets
    {cite}`arnold_factsheets_2019` provides templates for describing datasets
    and the AI models deployed increasing the transparency and
    accountability of experimentations and operational intelligent
    systems.

Below a few of the above guidelines are precised. Following
{cite}`heil_et_al_2021`'s proposal, the three degrees of the reproducibility
standards for ML are based on availability of data, model, and code, as
well as other analyses or programming dependencies. For instance, in the
bronze standards (the minimal requirements for reproducibility) the
authors should make the data, model and its source code publicly
available for downloading. The silver standard extends it by
additionally providing: dependencies of the analysis (in a form to be
installed in a single command), recording key details of the analysis
and used software requirements. Furthermore, all elements in the
analysis should be documented to be set deterministic. Within the gold
standard the authors should also prepare this analysis reproducible with
a single command - which is the most demanding with respect to full
automatization of the reproducibility process.

{cite}`pineau_et_al_2020` specify the necessary elements to be documented and
made public with respect to the following categories: model and
algorithm, theoretical claims, datasets used in experiments, shared code
including dependencies specifications, all reported experimental results
(with all details for the experimental setup, hyper-parameters, training
details, definitions of evaluation measures, and description of the
computing infrastructure used). {cite}`Lynnerup_et_al_2020` provide similar
recommendations for ML in robotics, by focusing on the reproducibility
of computation experiments on real robots. They stress the role of
managing properly the software dependencies, distinguishing between
experimental code and library code, and documenting the measurement
metrics, which is essential for reinforcement learning.

Datasheets by {cite}`gebru_datasheets_2020` specify how to document the
motivation, composition, collection process, recommended uses for data
deployed in the systems and experiments; model cards by
{cite}`mitchell_modelcards_2019` ease the description of model's intended use
cases limiting their usage in contexts for which they are not well
suited; factsheets {cite}`arnold_factsheets_2019` provide a template for
describing the purpose, performance, safety, security, and provenance
information to be completed by AI service providers for examination by
consumers.

## Bibliography

```{bibliography}
:style: unsrt
:filter: docname in docnames
```
