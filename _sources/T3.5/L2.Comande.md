---
author:
- 'Roberto Pellungrini, Francesca Pratesi, Anna Monreale'
bibliography:
- 'references.bib'
title: '**Taylor Encyclopedia excerpt**'
---

\maketitle
Pseudonymisation
================

To preserve a subject's privacy, one of the most basic methodology is to
de-couple the identity of said subject from its data. This is process is
called pseudonymisation. The typical practical approach to achieve
pseudonymity is to detect which attributes in the data may reveal the
subject's identity, called *personal identifiers*, and substitute them
with some other value. The goal is to reduce the risk of a direct
re-identification of the data subjects based on the published data.
However, re-identification may be needed in certain cases, therefore
personal identifiers are often maintained for re-associating subject and
identity. This association should be secured and inaccessible to anybody
having access tho the pseudonymised data, so that protection is
guaranteed. Following the description in the articles 4(5) of the
European General Data Protection Regulation (GDPR):

"the processing of personal data in such a manner that the personal data
can no longer be attributed to a specific data subject without the use
of additional information, provided that such additional information is
kept separately and is subject to technical and organisational measures
to ensure that the personal data are not attributed to an identified or
identifiable natural person".

This definition indicates that the additional information needed to
actually link a subject's identity to it's data should be the focus of
pseudonymisation techniques.

Additional information makes the difference between *pseudonymised* and
*anonymised* data. Anonymous data are deprived of all distinctive
elements of the person, i.e., those elements that permit to identify
both directly or indirectly that person in the data. Anonymous data
cannot be re-identified by definition, even when using additional
information, therefore this type of data is not subject to the privacy
regulations.

This key difference can be better understood with the famous real life
example of the attack on the privacy of the Governor of Massachussetts.
In 1996, *William Floyd Weld*, then Governor of Massachusetts, lost his
consciousness during a public event. Rushed to the nearby Deaconess
Waltham Hospital, he was officially diagnosed with influenza and
consequently discharged the following day {cite}`BarthJones2012`. Some time
later, professor Latanya Sweeney, a graduate computer science student at
MIT at the time, successfully reconstructed what had happened to the
governor and inferred his diagnosis linking two different data sources:
a publicly available voter rolls dataset and a hospital dataset then
considered anonymous {cite}`SweeneyGov`. The voter rolls dataset contained
the name, address, ZIP code, birth date, sex and other attributes of
every voter in the city of Cambridge (Middlesex County). The hospital
dataset was issued to researchers by the Massachusetts Group Insurance
Commission and contained diagnosis of patients along with personal
information. Since the identity of the different patients was not
present in the hospital data, the personal information published there
was considered harmless. Since Sweeney knew that the governor was
admitted to the hospital, she also knew he was present in the data.
Therefore, she intersected the demographic information in the two
dataset: six individuals in the hospital dataset shared the Governor's
birth date, only three of these were men but only one of the men lived
in the Governor's own ZIP code.

\centering
[\[tab\_roll\]]{#tab_roll label="tab_roll"}

   **Surname**     **Name**      **Date of birth**   **Sex**   **Address**    **ZIP code**   **Last vote**
  ------------- --------------- ------------------- --------- -------------- -------------- ---------------
       ...            ...               ...            ...         ...            ...             ...
      Weld       William Floyd     31 July 1945         M      75, Essex St      02139        3 May 1996
     Wellen          Alice          4 July 1950         F      455, Main St      02139        3 May 1996
      Welsh           Bob          15 July 1948         M      148, Gold Rd      02138        3 May 1996
       ...            ...               ...            ...         ...            ...             ...

  : Cambridge Voter Roll Dataset

\centering
[\[tab\_hosp\]]{#tab_hosp label="tab_hosp"}

   **Id**   **Sex**   **Date of birth**   **ZIP code**    **Visit**     **Diagnosis**
  -------- --------- ------------------- -------------- -------------- ---------------
    ...       ...            ...              ...            ...             ...
     1         M        31 July 1945         02138       1 April 1996     Diabetes
     2         M        31 July 1945         02139       18 May 1996       Stroke
     3         F        31 July 1945         02138       18 May 1996    Osteoporosis
     4         F        31 July 1945         02139       20 May 1996       Stroke
     5         M         1 May 1945          02138       2 June 1996      Diabetes
     6         M         3 June 1945         02139       7 June 1996      Arthritis
     7         F        1 April 1945         02139       4 July 1996    Hypertension
    ...       ...            ...              ...            ...             ...

  : Hospital Dataset

In Tables [\[tab\_roll\]](#tab_roll){reference-type="ref"
reference="tab_roll"} and
[\[tab\_hosp\]](#tab_hosp){reference-type="ref" reference="tab_hosp"} we
can see a simplified version of Sweeney's attack. We can see that,
matching the information colored in blue, there is no other possibility
for Governor Weld but to be a patient suffering from a stroke. This was
a clear breach of the privacy of the Governor, as the public statement
about his health differed from the actual cause of hospitalization.

Sweeney conducted similar attacks in a more structured and generalised
experiment, finding that 87% of the United States population was
uniquely or nearly uniquely identified by the combination of ZIP code,
gender, and date of birth {cite}`kanon`. This lead Sweeney to theorize the
k-anonymity principle, and call the attributes used for the
re-identification process *quasi-identifier*.

Recital 28 of the GDPR, states that "explicit introduction of
pseudonymisation in this Regulation is not intended to preclude any
other measures of data protection". Article 6(4) of the GDPR also
reports that pseudonymisation could be an "appropriate safeguards" and
that data controller should operate "pseudonymising personal data as
soon as possible" (Recital 78 GDPR) and implementing "appropriate
technical and organisational measures, such as pseudonymisation"
(Article 25(1) GDPR) both at the time of the determination of the means
for processing and at the time of the processing itself.

Pseudonymisation techniques
===========================

Pseudonymisation aims to substitute one or more identifiers that link
the identity of an individual to its data with a surrogate value, called
*pseudonym* or *token*, reducing the risk of publishing data allowing a
direct re-identification, i.e., without knowing external information, of
data subjects.

The pseudonym must be distinguishable and irreversible in the absence of
additional information. This means that it should not be possible to
reconstruct the original value by just considering the pseudonym, i.e.,
there does not exist any function that computes the original value with
the pseudonym as input. The correspondence between original value and
pseudonym must be stored in a separate location and must be secured
against data breaches. Surrogate values need also to be managed after
the generation, either internally or externally to the Data Provider.

There are several techniques that perform pseudonymisation. They can be
generally summarized in three main categories:

1.  **Cryptographic with secret key**: these techniques use mathematical
    mechanism to alter the original value through the application of a
    secret *key*. This key is at the core of the mechanism: with it, the
    pseudonymisation can be reversed, so the key has to be secured at
    all times.

2.  **Hash-based**: these techniques use a function that, given an
    identifier (composed by one or more attributes) with arbitrary
    length returns a value of fixed size (e.g. of size 256 bits, that is
    32 characters), being called hash value or message digest. The hash
    function is usually a deterministic function and must be
    irreversible, i.e., for any input of the function it is infeasible
    to compute the inverse function from the output. Functions typically
    used for hashing are *SHA-2* {cite}`SHA2` and *SHA-3* {cite}`SHA3`, for example
    the *SHA3-512* which has output values of length 512 bits.

3.  **Keyed-hash based**: a combination of the previous techniques where
    the hash function requires a key, called *salt* {cite}`Hmac`, to compute
    its output. This is generally considered a more robust approach that
    simple hashing. Varying the key, the same data subject's identifier
    can be translated in several different pseudonyms. In cryptography
    literature, these are referred to as *message authentication codes*
    {cite}`cripto`. This family of techniques is more robust against some
    brute-force attacks, especially if the salt is changed sufficiently
    often.

4.  **Keyed-hash function with deletion**: equal to the previous one,
    but after the generation of the pseudonym, the correspondence table
    is deleted, i.e., we cannot associate again pseudonyms to personal
    identifiers.

5.  **Tokenization**: the idea of tokenization is to substitute the
    subjects' identifiers with a token generated with some cryptographic
    methods. However, tokenization is a non-mathematical approach: data
    is replaced but the type or length is not altered. Typically
    knowledge of a token has no usefulness for a third party. Another
    difference is that tokenization is fast and can be done with few
    computational resources.{cite}`tokens`

\bibliographystyle{abbrv}
